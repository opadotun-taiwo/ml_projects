{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42398ae1-ecb8-4802-9abe-fe3a7660a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 16:33:52.779114: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-30 16:33:53.066466: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 16:34:12.586924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-30 16:34:25.150552: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 16:34:25.151621: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105f2445-12f8-4e9f-91bb-8bbe74ce42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/alexeygrigorev/clothing-dataset-small.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7dc6a95-69aa-4ba4-9009-4272190e500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc9394c-7611-4e58-8a60-86c21458adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './clothing-dataset-small/train/t-shirt/'\n",
    "name = '5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg'\n",
    "full_name = f'{path}/{name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee41e302-f33e-4083-bfec-f939555c54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(full_name, target_size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8868186-866c-49fa-bcbf-cca00c176a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=299x299 at 0x7A892EF43FE0>\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a733b7-3101-4b12-b13f-a422d08f1130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88568091-2856-4ae4-b702-55d55d6f660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 16:34:35.442337: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8314b9a-8b0f-416b-8085-152fce5a0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Xception(weights='imagenet', input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2178ba-937e-46bf-b268-5ec5eceba06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5ecfc07-f10a-4698-ae78-1d36572e5f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.4039216 ,  0.3411765 , -0.2235294 ],\n",
       "        [ 0.4039216 ,  0.3411765 , -0.2235294 ],\n",
       "        [ 0.41960788,  0.35686278, -0.20784312],\n",
       "        ...,\n",
       "        [ 0.96862745,  0.9843137 ,  0.94509804],\n",
       "        [ 0.96862745,  0.9843137 ,  0.94509804],\n",
       "        [ 0.96862745,  0.99215686,  0.9372549 ]],\n",
       "\n",
       "       [[ 0.47450984,  0.4039216 , -0.12156862],\n",
       "        [ 0.4666667 ,  0.39607847, -0.12941176],\n",
       "        [ 0.45882356,  0.38823533, -0.15294117],\n",
       "        ...,\n",
       "        [ 0.96862745,  0.9764706 ,  0.9372549 ],\n",
       "        [ 0.96862745,  0.9764706 ,  0.9372549 ],\n",
       "        [ 0.96862745,  0.9764706 ,  0.92941177]],\n",
       "\n",
       "       [[ 0.56078434,  0.48235297, -0.00392157],\n",
       "        [ 0.5686275 ,  0.4901961 ,  0.00392163],\n",
       "        [ 0.5686275 ,  0.49803925, -0.01176471],\n",
       "        ...,\n",
       "        [ 0.9607843 ,  0.96862745,  0.92156863],\n",
       "        [ 0.9607843 ,  0.96862745,  0.92156863],\n",
       "        [ 0.9607843 ,  0.96862745,  0.92156863]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.2941177 ,  0.18431377, -0.40392154],\n",
       "        [ 0.35686278,  0.24705887, -0.34117645],\n",
       "        [ 0.3411765 ,  0.2313726 , -0.35686272],\n",
       "        ...,\n",
       "        [ 0.43529415,  0.05882359, -0.8039216 ],\n",
       "        [ 0.41960788,  0.04313731, -0.827451  ],\n",
       "        [ 0.43529415,  0.05882359, -0.8117647 ]],\n",
       "\n",
       "       [[ 0.2941177 ,  0.18431377, -0.40392154],\n",
       "        [ 0.35686278,  0.24705887, -0.34117645],\n",
       "        [ 0.3411765 ,  0.2313726 , -0.35686272],\n",
       "        ...,\n",
       "        [ 0.427451  ,  0.05098045, -0.81960785],\n",
       "        [ 0.41176474,  0.03529418, -0.8352941 ],\n",
       "        [ 0.427451  ,  0.05098045, -0.81960785]],\n",
       "\n",
       "       [[ 0.2941177 ,  0.18431377, -0.40392154],\n",
       "        [ 0.35686278,  0.24705887, -0.34117645],\n",
       "        [ 0.3411765 ,  0.2313726 , -0.35686272],\n",
       "        ...,\n",
       "        [ 0.41960788,  0.04313731, -0.827451  ],\n",
       "        [ 0.4039216 ,  0.02745104, -0.84313726],\n",
       "        [ 0.427451  ,  0.05098045, -0.81960785]]],\n",
       "      shape=(299, 299, 3), dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocess_input(X)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7a272e-34df-4628-93f5-7e8014582ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9133f29b-621b-41d2-b8f2-6f17af70ca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n03595614', 'jersey', np.float32(0.68196297)),\n",
       "  ('n02916936', 'bulletproof_vest', np.float32(0.03814005)),\n",
       "  ('n04370456', 'sweatshirt', np.float32(0.034324754)),\n",
       "  ('n03710637', 'maillot', np.float32(0.011354217)),\n",
       "  ('n04525038', 'velvet', np.float32(0.0018453607))]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78b20ce9-209f-48a1-b092-faa1ab9e53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2667537f-d13d-4302-9688-4958ff74f508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3073 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_ds = train_gen.flow_from_directory('./clothing-dataset-small/train/', target_size=(150, 150), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb97f60-f7fa-4537-8bc6-5abeb5545edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 0,\n",
       " 'hat': 1,\n",
       " 'longsleeve': 2,\n",
       " 'outwear': 3,\n",
       " 'pants': 4,\n",
       " 'shirt': 5,\n",
       " 'shoes': 6,\n",
       " 'shorts': 7,\n",
       " 'skirt': 8,\n",
       " 't-shirt': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d176048-2936-46f0-9bd0-b89ce1e1e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c5d219-4aa7-46c1-9e92-1b22b88ecad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 150, 150, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0160c5e0-afd0-44e7-86ea-cf542915aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 341 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_ds = val_gen.flow_from_directory('./clothing-dataset-small/validation/', target_size=(150, 150), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5805446-86a6-4507-acde-1f0fa3f4934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "#4 dimension\n",
    "base = base_model(inputs, training=False)\n",
    "\n",
    "#turns into 1 dimension\n",
    "vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "outputs = keras.layers.Dense(10)(vectors)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35b4b4b6-7ac6-4e30-9381-636b8c6a3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "283b9268-ac37-453b-a346-4f81c1d0bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_ds, epochs=3, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3bbb425-e4af-44c0-80a8-2428de2b1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['accuracy'], label='Train')\n",
    "#plt.plot(history.history['val_accuracy'], label='Val')\n",
    "#plt.xticks(np.arange(10))\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05b2dd39-e8d4-4555-a8b0-67716d724b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate=0.01):\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    ################################################################\n",
    "    inputs = keras.Input(shape=(150, 150, 3))\n",
    "    \n",
    "    #4 dimension\n",
    "    base = base_model(inputs, training=False)\n",
    "    \n",
    "    #turns into 1 dimension\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(vectors)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    ################################################################\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "036d53ed-0826-4803-9b81-13db234234af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscores = {}\\n\\nfor lr in [0.001, 0.01, 0.1]:\\n    print(lr)\\n\\n    model = make_model(learning_rate=lr)\\n    history = model.fit(train_ds, epochs=3, validation_data=val_ds)\\n    scores[lr] = history.history\\n\\n    print()\\n    print()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scores = {}\n",
    "\n",
    "for lr in [0.001, 0.01, 0.1]:\n",
    "    print(lr)\n",
    "\n",
    "    model = make_model(learning_rate=lr)\n",
    "    history = model.fit(train_ds, epochs=3, validation_data=val_ds)\n",
    "    scores[lr] = history.history\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "278c2080-6435-4cd7-a050-cadf9077f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57e1392f-2922-4fe9-a952-e95e986aa3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor lr, hist in scores.items():\\n    print(lr)\\n    print(hist)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for lr, hist in scores.items():\n",
    "    print(lr)\n",
    "    print(hist)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a94aee5-88e7-4d0f-be1e-10eb4ff325f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor lr, hist in scores.items(): \\n    #plt.plot(hist['accuracy'], label=('train=%s' % lr))\\n    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\\n    plt.xticks(np.arange(10))\\n    plt.legend()\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for lr, hist in scores.items(): \n",
    "    #plt.plot(hist['accuracy'], label=('train=%s' % lr))\n",
    "    plt.plot(hist['val_accuracy'], label=('val=%s' % lr))\n",
    "    plt.xticks(np.arange(10))\n",
    "    plt.legend()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9800fee-ea73-452b-8a72-8f1aca053b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_v1.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b367ce09-c261-4c4d-9f87-d2ffd8a0b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'xception_v1_{epoch:02d}_{val_accuracy:.3f}.h5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f7ee5-9828-4245-9fea-f37050ab0da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m81/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.4936 - loss: 1.5041"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = make_model(learning_rate=learning_rate)\n",
    "history = model.fit(train_ds, epochs=5, validation_data=val_ds)\n",
    "callbacks=[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372026fc-08c0-42ba-b6fb-36eb85917d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef5330-3182-4ef8-9aa9-3cddcb981eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
